# main_simple.py
# Wersja 2.0: Zintegrowany finalny, dopracowany potok przetwarzania wstƒôpnego audio.

import os
from datetime import datetime
import configparser
import sys
import time
import numpy as np
import noisereduce as nr
import sounddevice as sd
import pyperclip
import subprocess
import threading
from faster_whisper import WhisperModel
from pydub import AudioSegment
from pydub.effects import normalize
from pynput import keyboard
from scipy.io.wavfile import write

# --- Globalne Zmienne ---
model = None
is_recording = False
audio_frames = []
app_settings = {}

# --- Finalne Parametry Potoku (ustalone na podstawie test√≥w) ---
SAMPLE_RATE = 16000             # [Hz] Czƒôstotliwo≈õƒá pr√≥bkowania; standard dla modeli mowy.
DEESSER_THRESH_DB = -43         # [dB] Pr√≥g g≈Ço≈õno≈õci, powy≈ºej kt√≥rego de-esser zaczyna t≈Çumiƒá syki.
DEESSER_ATTENUATION_DB = 13     # [dB] Si≈Ça, z jakƒÖ de-esser ≈õcisza wykryte sybilanty.
DEESSER_FREQ_START = 6000       # [Hz] Dolna granica pasma czƒôstotliwo≈õci, w kt√≥rym dzia≈Ça de-esser.
DEESSER_FREQ_END = 10000        # [Hz] G√≥rna granica pasma czƒôstotliwo≈õci, w kt√≥rym dzia≈Ça de-esser.
DEESSER_ATTACK_MS = 10          # [ms] Czas potrzebny na osiƒÖgniƒôcie pe≈Çnego t≈Çumienia (wyg≈Çadza poczƒÖtek).
DEESSER_RELEASE_MS = 30         # [ms] Czas powrotu do normalnej g≈Ço≈õno≈õci (wyg≈Çadza koniec, eliminuje trzaski).
FINAL_GAIN_DB = 6.0             # [dB] Ko≈Ñcowe podbicie g≈Ço≈õno≈õci ca≈Çego nagrania po przetworzeniu.
# DEPLOSER_FREQ = 100           # [Hz] De-ploser obecnie nieu≈ºywany, ale parametr zostaje na przysz≈Ço≈õƒá.

# --- Funkcje Przetwarzania Wstƒôpnego Audio ---

def dynamic_de_esser_smooth(audio_segment, threshold_db, freq_start, freq_end, attenuation_db, attack_ms, release_ms):
    """Ulepszony de-esser z wyg≈Çadzaniem (attack/release) w celu unikniƒôcia trzask√≥w."""
    sibilance_band = audio_segment.high_pass_filter(freq_start).low_pass_filter(freq_end)
    chunk_length_ms = 10
    is_attenuating = False
    processed_audio = AudioSegment.empty()
    for i in range(0, len(audio_segment), chunk_length_ms):
        chunk_original = audio_segment[i:i+chunk_length_ms]
        chunk_sibilance = sibilance_band[i:i+chunk_length_ms]
        should_attenuate = chunk_sibilance.dBFS > threshold_db
        if should_attenuate and not is_attenuating:
            chunk_attenuated = chunk_original - attenuation_db
            transition = chunk_original.fade(to_gain=-120, start=0, duration=attack_ms).overlay(chunk_attenuated.fade(from_gain=-120, start=0, duration=attack_ms))
            processed_audio += transition
            is_attenuating = True
        elif not should_attenuate and is_attenuating:
            chunk_attenuated = chunk_original - attenuation_db
            transition = chunk_attenuated.fade(to_gain=-120, start=0, duration=release_ms).overlay(chunk_original.fade(from_gain=-120, start=0, duration=release_ms))
            processed_audio += transition
            is_attenuating = False
        elif is_attenuating:
            processed_audio += (chunk_original - attenuation_db)
        else:
            processed_audio += chunk_original
    return processed_audio

def apply_preprocessing_pipeline(audio_data_float32):
    """Stosuje pe≈Çny potok przetwarzania wstƒôpnego do surowych danych audio."""
    print("üîä Uruchamianie potoku przetwarzania wstƒôpnego audio...")
    try:
        audio_data_int16 = np.int16(audio_data_float32 * 32767)
        audio_segment = AudioSegment(
            audio_data_int16.tobytes(), 
            frame_rate=SAMPLE_RATE,
            sample_width=audio_data_int16.dtype.itemsize, 
            channels=1
        )
        
        print("   - Krok 1: Normalizacja g≈Ço≈õno≈õci...")
        normalized_segment = normalize(audio_segment)
        
        print(f"   - Krok 2: Aplikowanie de-essera z wyg≈Çadzaniem...")
        deessed_segment = dynamic_de_esser_smooth(
            normalized_segment, 
            DEESSER_THRESH_DB, 
            DEESSER_FREQ_START, 
            DEESSER_FREQ_END, 
            DEESSER_ATTENUATION_DB, 
            DEESSER_ATTACK_MS, 
            DEESSER_RELEASE_MS
        )
        
        print(f"   - Krok 3: Podbicie g≈Ço≈õno≈õci o +{FINAL_GAIN_DB} dB...")
        boosted_segment = deessed_segment + FINAL_GAIN_DB

        processed_before_nr = np.array(boosted_segment.get_array_of_samples(), dtype=np.float32) / 32767.0
        
        print("   - Krok 4: Aplikowanie redukcji szumu...")
        noise_clip = processed_before_nr[:int(SAMPLE_RATE * 0.5)]
        final_audio_float32 = nr.reduce_noise(
            y=processed_before_nr,
            y_noise=noise_clip,
            sr=SAMPLE_RATE,
            prop_decrease=0.85
        )
        
        print("üîä Przetwarzanie wstƒôpne zako≈Ñczone pomy≈õlnie.")
        return final_audio_float32

    except Exception as e:
        print(f"‚ö†Ô∏è OSTRZE≈ªENIE: Przetwarzanie wstƒôpne nie powiod≈Ço siƒô: {e}.")
        print("   U≈ºywanie oryginalnego, surowego audio.")
        return audio_data_float32

# --- G≈Ç√≥wne Funkcje Aplikacji (bez zmian) ---

def load_configuration():
    config = configparser.ConfigParser()
    try:
        config.read('config.ini')
        settings = {
            'model_path': config.get('settings', 'model_path', fallback='small'),
            'device': config.get('settings', 'device', fallback='cuda'),
            'compute_type': config.get('settings', 'compute_type', fallback='int8'),
            'hotkey': config.get('settings', 'hotkey', fallback='<ctrl>+f8'),
            'language': config.get('settings', 'language', fallback='pl'),
        }
        print("Konfiguracja za≈Çadowana pomy≈õlnie.")
        return settings
    except (FileNotFoundError, configparser.Error) as e:
        print(f"B≈ÇƒÖd wczytywania config.ini: {e}")
        sys.exit(1)

def load_model(settings):
    global model
    model_path = settings['model_path']
    device = settings['device']
    compute_type = settings['compute_type']
    print("\n--- ≈Åadowanie Modelu ---")
    print(f"Pr√≥ba za≈Çadowania modelu: '{model_path}'")
    print(f"UrzƒÖdzenie: '{device}', Typ oblicze≈Ñ: '{compute_type}'")
    start_time = time.time()
    try:
        model = WhisperModel(model_path, device=device, compute_type=compute_type)
        end_time = time.time()
        print(f"‚úÖ Model za≈Çadowany pomy≈õlnie w {end_time - start_time:.2f}s.")
    except Exception as e:
        print(f"‚ùå B≈ÅƒÑD KRYTYCZNY: Nie uda≈Ço siƒô za≈Çadowaƒá modelu Whisper: {e}")
        sys.exit(1)

def record_and_transcribe(settings):
    global audio_frames
    print("\nüéôÔ∏è  Nagrywanie... M√≥w teraz.")
    audio_frames = []
    def audio_callback(indata, frames, time, status):
        if status:
            print(f"Status strumienia audio: {status}", file=sys.stderr)
        audio_frames.append(indata.copy())
    stream = sd.InputStream(samplerate=SAMPLE_RATE, channels=1, dtype='float32', callback=audio_callback)
    stream.start()
    while is_recording:
        time.sleep(0.1)
    stream.stop()
    stream.close()
    print("üéôÔ∏è  Nagrywanie zatrzymane.")
    if not audio_frames:
        print("Nie nagrano ≈ºadnego d≈∫wiƒôku.")
        return
    raw_audio_data = np.concatenate(audio_frames, axis=0).flatten().astype(np.float32)
    processed_audio = apply_preprocessing_pipeline(raw_audio_data)
    output_dir = "outputs"
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    wav_filename = os.path.join(output_dir, f"rec_{timestamp}.wav")
    txt_filename = os.path.join(output_dir, f"rec_{timestamp}.txt")
    try:
        write(wav_filename, SAMPLE_RATE, (processed_audio * 32767).astype(np.int16))
        print(f"‚úÖ Przetworzone audio zapisano w: {wav_filename}")
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd podczas zapisywania pliku audio: {e}")
    print("üß† Rozpoczynanie transkrypcji...")
    start_time = time.time()
    segments, _ = model.transcribe(
        processed_audio,
        language=settings['language'],
        beam_size=5,
        temperature=0.0,
        compression_ratio_threshold=2.4,
        log_prob_threshold=-1.0,
        no_speech_threshold=0.6
    )
    end_time = time.time()
    final_text = "".join(segment.text for segment in segments).strip()
    print(f"üß† Transkrypcja zako≈Ñczona w {end_time - start_time:.2f}s.")
    try:
        with open(txt_filename, "w", encoding="utf-8") as f:
            f.write(final_text)
        print(f"‚úÖ Transkrypcja zapisana w: {txt_filename}")
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd podczas zapisywania pliku transkrypcji: {e}")
    print("\n--- Wynik Ko≈Ñcowy ---")
    print(f"Tekst: {final_text}")
    if final_text:
        pyperclip.copy(final_text)
        print("‚úÖ Skopiowano do schowka.")
        try:
            time.sleep(0.1)
            subprocess.run(["xdotool", "type", "--clearmodifiers", final_text], check=True)
            print("‚úÖ Wklejono do aktywnego okna.")
        except FileNotFoundError:
            print("‚ùå B≈ÅƒÑD: Polecenie 'xdotool' nie zosta≈Ço znalezione.")
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas wklejania tekstu: {e}")

def start_recording_flag():
    global is_recording
    if not is_recording:
        is_recording = True
        threading.Thread(target=record_and_transcribe, args=(app_settings,)).start()

def stop_recording_flag():
    global is_recording
    if is_recording:
        is_recording = False

if __name__ == "__main__":
    print("--- Uruchamianie Lokalnego Asystenta Dyktowania (Wersja Wsadowa) ---")
    app_settings = load_configuration()
    load_model(app_settings)
    hotkey_str = app_settings['hotkey']
    print(f"\n‚úÖ Gotowy. Naci≈õnij i przytrzymaj '{hotkey_str}', aby nagrywaƒá. Pu≈õƒá, aby transkrybowaƒá.")
    print("Naci≈õnij Ctrl+C, aby wyj≈õƒá.")
    HOTKEY_COMBINATION = {keyboard.Key.ctrl, keyboard.Key.f8}
    current_keys = set()
    def on_press(key):
        if key in HOTKEY_COMBINATION:
            current_keys.add(key)
            if all(k in current_keys for k in HOTKEY_COMBINATION):
                start_recording_flag()
    def on_release(key):
        try:
            if key in HOTKEY_COMBINATION:
                stop_recording_flag()
                current_keys.clear()
        except KeyError:
            pass
    with keyboard.Listener(on_press=on_press, on_release=on_release) as listener:
        listener.join()